{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb32a73-5159-41ae-8ae2-1c6c91f46ff8",
   "metadata": {},
   "source": [
    "### Tensor Decomposition Class\n",
    "\n",
    "Circa, November 2, 2021\n",
    "\n",
    "Author: Lekan Molux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4607c-a23c-4c2c-8d40-06bb18049055",
   "metadata": {},
   "source": [
    "### [Usefuls]()\n",
    "\n",
    "+ [Accelerating Deep Neural Networks with Tensor Decompositions](https://jacobgil.github.io/deeplearning/tensor-decompositions-deep-learning)\n",
    "+ [Einstein Py](https://github.com/einsteinpy/einsteinpy)\n",
    "+ [Projection on Tensor Product of Hilbert Space](https://math.stackexchange.com/questions/333537/projection-on-tensor-product-of-hilbert-space)\n",
    "+ [Tensor Decomposition for Signal Processing and Machine Learning](https://arxiv.org/pdf/1607.01668.pdf)\n",
    "+ [Tucker Compression Deep Learning](https://github.com/kittygo/tensor_decompostion/blob/master/tucker_compression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5cd2cf-15c9-4bf3-9f2a-2a709d92086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import sys, copy\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Utilities import *\n",
    "from Tensors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f02376-25ef-489e-9a70-28d259449551",
   "metadata": {},
   "outputs": [],
   "source": [
    "X12 = np.arange(1, 25).reshape(3, 4, 2, order='F')\n",
    "U = np.arange(1, 7).reshape(2, 3, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f6714-3e8a-4398-8cd2-ca8221410f2a",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1486bd0a-b07a-4e57-80de-fe167e2ca97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mode_1_fiber: \n",
      " [[ 1  4  7 10 13 16 19 22]\n",
      " [ 2  5  8 11 14 17 20 23]\n",
      " [ 3  6  9 12 15 18 21 24]]\n",
      "\n",
      "mode_2_fiber: \n",
      " [[ 1  2  3 13 14 15]\n",
      " [ 4  5  6 16 17 18]\n",
      " [ 7  8  9 19 20 21]\n",
      " [10 11 12 22 23 24]]\n",
      "\n",
      "mode_3_fiber \n",
      " [[ 1  4  7 10  2  5  8 11  3  6  9 12]\n",
      " [13 16 19 22 14 17 20 23 15 18 21 24]]\n"
     ]
    }
   ],
   "source": [
    "#1-mode unfold\n",
    "\n",
    "mode_1_fiber = matricization(X12, mode='1')\n",
    "print('\\nmode_1_fiber: \\n', mode_1_fiber)\n",
    "\n",
    "#2-mode unfold\n",
    "\n",
    "mode_2_fiber = matricization(X12, mode='2')\n",
    "print('\\nmode_2_fiber: \\n', mode_2_fiber)\n",
    "\n",
    "#3-mode unfold\n",
    "mode_3_fiber = matricization(X12, mode='3')\n",
    "print('\\nmode_3_fiber \\n', mode_3_fiber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c119a53e-2115-4dd5-8709-15600c6efb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = npr.rand(5,3,4,2)\n",
    "A = npr.rand(4,5); B =  npr.rand(4,3); C =  npr.rand(3,4); D =  npr.rand(3,2);\n",
    "V = np.asarray([A, B, C, D], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb6562-5dbb-40aa-b863-f04463f760dc",
   "metadata": {},
   "source": [
    "### Test Tensor-Matrix Multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fc54eb-69d7-42a7-ac33-eeaa5955b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = npr.rand(5, 3, 4, 2)\n",
    "A = npr.rand(4, 5); B = npr.rand(4, 3); C = npr.rand(3, 4); D = npr.rand(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8242e8df-22ae-45a7-8a6e-96d164569aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 4, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tensor_matrix_mult(X, A, n=0, Transpose=False)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0e6751-ea78-4bfc-8f56-693d1b0c5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = npr.rand(3,3,3)\n",
    "A = npr.rand(3,3)\n",
    "T = tensor_matrix_mult(X, A, n=1, Transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c21d6bd-745c-448e-9001-f4f1392203b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above\n",
    "T = tensor_matrix_mult(X, A.T, n=0, Transpose=True)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05365d-ab16-46a4-a317-74c1399e1657",
   "metadata": {},
   "source": [
    "#### Tensor by Block matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936cc288-106f-42e9-8a93-44f1288b9ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot deduce data type of V.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d01c3fd914ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_matrix_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Control-Rob/Reachability/LevelSetPy/Tensors/tensor_mat_mult.py\u001b[0m in \u001b[0;36mtensor_matrix_mult\u001b[0;34m(X, V, n, Transpose, use_gpu)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot deduce data type of V.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot deduce data type of V."
     ]
    }
   ],
   "source": [
    "T = tensor_matrix_mult(X, np.asarray([A, B, C, D], dtype=object), n=[0, 1, 2, 3])\n",
    "\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249cf22-6f18-4070-a518-81e84d48379b",
   "metadata": {},
   "source": [
    "### Tucker Decomposition\n",
    "\n",
    "For a tensor $\\mathcal{X}$, the higher-order SVD for $\\mathcal{X}$ is generated by decomposing it into a core tensor multiplied by a matrix along each mode. For a 3D tensor, $\\mathcal{X} \\in \\mathbb{R}^{I \\times J \\times K}$, we have\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{X} = \\mathcal{G} \\times_1 A \\times_2 B \\times_3 C = \\sum_{p=1}^P \\sum_{q=1}^Q \\sum_{r=1}^R g_{pqr} \\, a_p \\circ b_q \\circ c_r = [\\mathcal{G}; A, B, C ]\n",
    "\\end{align}\n",
    "\n",
    "where $A \\in \\mathbb{R}^{I \\times P}, B \\in \\mathbb{R}^{J\\times Q}$, and $C=B \\in \\mathbb{R}^{K\\times R}$ are the factor matrices (typically orthogonal:=principal components in each mode).  $\\mathcal{G}  \\in \\mathbb{R}^{P \\times Q \\times R}$ is the core tensor, and its entries show the level of interaction between the different components.\n",
    "\n",
    "Elementwise, we write the Tucker decomposition as \n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{x}_{ijk} = \\sum_{p=1}^P \\sum_{q=1}^Q \\sum_{r=1}^R \\mathcal{g}_{pqr} \\, a_{ip} \\circ b_{jq} \\circ c_{kr}  \\forall \\, i = 1, \\cdots, I, j= 1, \\cdots J, k = 1, \\cdots, K.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c46c2c-f86c-4095-b8e6-64529a4a53d4",
   "metadata": {},
   "source": [
    "In matricized form, we have per mode of each of the decomposition for a 3D tensor as\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathcal{X}_{(1)} &\\approx  A \\, \\mathcal{G}_{(1)} \\, \\left(C \\otimes B\\right)^T \\\\\n",
    "    \\mathcal{X}_{(2)} &\\approx  B \\, \\mathcal{G}_{(2)} \\, \\left(C \\otimes A\\right)^T \\\\\n",
    "    \\mathcal{X}_{(3)} &\\approx  C \\, \\mathcal{G}_{(3)} \\, \\left(B \\otimes A\\right)^T \\\\\n",
    "\\end{align}\n",
    "\n",
    "where $\\otimes$ is the matrix Kronecker product defined for a matrix $F \\in \\mathbb{R}^{I\\times J}$ and $G \\in \\mathbb{R}^{K\\times L}$ as, \n",
    "\n",
    "\\begin{align}\n",
    "   F \\otimes G &=\\begin{bmatrix}\n",
    "                    f_{11} \\otimes G &  f_{12} \\otimes G &  f_{13} \\otimes G & \\cdots &  f_{1J} \\otimes G \\\\\n",
    "                    f_{21} \\otimes G &  f_{22} \\otimes G &  f_{23} \\otimes G & \\cdots &  f_{2J} \\otimes G \\\\\n",
    "            \\vdots &  \\vdots  &  \\vdots  & \\ddots &  \\vdots \\\\\n",
    "                    f_{I1} \\otimes G &  f_{I2} \\otimes G &  f_{I3} \\otimes G & \\cdots &  f_{IJ} \\otimes G \n",
    "                 \\end{bmatrix}  \\\\\n",
    "                 %\n",
    "              &=   \\begin{bmatrix}\n",
    "                       f_1 \\otimes g_1 & f_1 \\otimes g_2 & f_1 \\otimes g_3 & \\cdots & f_J \\otimes g_{L-1} & f_J \\otimes g_{L}\n",
    "                 \\end{bmatrix} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324a1a3-f9db-4ff0-982b-0c8ddba0aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_matrix_mult(X, V, n=None, Transpose=False, use_gpu=True):\n",
    "    \"\"\"\n",
    "    tensor_matrix_mult: Tensor times matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: Tensor with N modes\n",
    "        V: 2D array\n",
    "        n: mode of tensor X to which to multiply the matrix by\n",
    "        Transpose: Should we rotate the matrix before multiplying? If we do rotate,\n",
    "                    then the tensor product is carried out from left to right in order;\n",
    "                    otherwise, it is carried out in order from right to left.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        T: A Tensor class which is the product of the\n",
    "            Tensor-Matrix multiplication.\n",
    "\n",
    "       Y = tensor_matrix_mult(X,A,N) computes the n-mode product of tensor X with a\n",
    "       matrix A; i.e., X x_N A.  The integer N specifies the dimension\n",
    "       (or mode) of X along which A should be multiplied.  If shape(A) =\n",
    "       (J,I), then X must have shape(X[N]) = I.  The result will be the\n",
    "       same order and shape as X except that shape(Y[N]) = J.\n",
    "\n",
    "       Y = tensor_matrix_mult(X,[A,B,C,...]) computes the n-mode product of tensor X\n",
    "       with a sequence of matrices in the list of array.  The n-mode\n",
    "       products are computed sequentially along all dimensions (or modes)\n",
    "       of X. The list of arrays contain X.ndim matrices.\n",
    "\n",
    "       Y = tensor_matrix_mult(X,[A,B,C,...],DIMS) computes the sequence tensor-matrix\n",
    "       products along the dimensions specified by DIMS.\n",
    "\n",
    "       Y = tensor_matrix_mult(...,'T') performs the same computations as above except\n",
    "       the matrices are transposed.\n",
    "\n",
    "       Examples\n",
    "       import numpy.random as npr\n",
    "       X = npr.rand(5,3,4,2)\n",
    "       A = npr.rand(4,5); B = npr.rand(4,3); C = npr.rand(3,4); D = npr.rand(3,2);\n",
    "       Y = tensor_matrix_mult(X, A, 1)         <-- computes X times A in mode-1\n",
    "       Y = tensor_matrix_mult(X, [A,B,C,D], 1) <-- same as above\n",
    "       Y = tensor_matrix_mult(X, A.T, 1, Transpose)   <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [A,B,C,D], [1, 2, 3, 4]) <-- 4-way multiply\n",
    "       Y = tensor_matrix_mult(X, [D,C,B,A], [4, 3, 2, 1]) <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [A,B,C,D])            <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [A',B',C',D'], Transpose=True)   <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [C,D], [3, 4])     <-- X times C in mode-3 & D in mode-4\n",
    "       Y = tensor_matrix_mult(X, [A,B,C,D], [3, 4]) <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [A,B,D], [1, 2, 4])   <-- 3-way multiply\n",
    "       Y = tensor_matrix_mult(X, [A,B,C,D], [1, 2, 4]) <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [A,B,D], -3)        <-- same as above\n",
    "       Y = tensor_matrix_mult(X, [A,B,C,D], -3)      <-- same as above\n",
    "\n",
    "       Author: Lekan Molux, November 1, 2021\n",
    "    \"\"\"\n",
    "    if isinstance(X, Tensor):\n",
    "        # Do all ops on numpy or cp array\n",
    "        X = X.data\n",
    "\n",
    "    if n is None:\n",
    "        n = np.arange(X.ndim)\n",
    "\n",
    "    if V.dtype=='O':\n",
    "\n",
    "        dims = n\n",
    "        dims,vidx = dims_check(dims,X.ndim,numel(V))\n",
    "\n",
    "        # Calc individual tensor products\n",
    "        Y = tensor_matrix_mult(X, V[vidx[0]], dims[0], Transpose)\n",
    "\n",
    "        for k in range(1, numel(dims)):\n",
    "            Y = tensor_matrix_mult(Y, V[vidx[k]], dims[k], Transpose)\n",
    "        return Y\n",
    "\n",
    "    if V.ndim>2:\n",
    "        raise ValueError(f'Tensor by Matrix multiplication does not support non-matrix as second argument.')\n",
    "\n",
    "    if (numel(n)!=1 or (n<0) or n > X.ndim):\n",
    "        raise ValueError(f'Dimension N: {N} of Tensor, must be between 1 and {X.ndim}.');\n",
    "\n",
    "    # Get Single n-mode product\n",
    "    N = X.ndim\n",
    "    sz = list(X.shape)\n",
    "\n",
    "    if n==N:\n",
    "        raise ValueError(f\"n: {n} cannot be same size as Tensor dimensions: {N}\"\n",
    "                         f\"n  should be at most {X.ndim-1}\")\n",
    "\n",
    "    if Transpose:\n",
    "        p = V.shape[1]\n",
    "    else:\n",
    "        p = V.shape[0]\n",
    "\n",
    "    if np.isscalar(n) and n==0:\n",
    "        A = X.reshape(sz[n], -1)\n",
    "        if Transpose:\n",
    "            B = V.T@A\n",
    "        else:\n",
    "            B = V@A\n",
    "    elif np.isscalar(n) and n==N-1:\n",
    "        At = X.reshape(-1, sz[n])\n",
    "        if Transpose:\n",
    "            B = At@V\n",
    "        else:\n",
    "            B = At@V.T\n",
    "    else:\n",
    "        to_tensor = False\n",
    "        nblocks   = int(np.prod(sz[n+1:]))\n",
    "        ncols = int(np.prod(sz[:n]))\n",
    "        nAk       = sz[n] * ncols\n",
    "        nBk       = p  *  ncols\n",
    "        B         = cp.zeros((p * nblocks * ncols, 1)) if use_gpu else np.zeros((p * nblocks * ncols, 1))\n",
    "\n",
    "        for k in range(nblocks):\n",
    "            # Extract k-th sub-block of A (in column-major order)\n",
    "            Akt_slice = slice((k) * nAk, (k+1)*nAk)\n",
    "            Akt = X.flatten()[Akt_slice].reshape(ncols, sz[n])\n",
    "\n",
    "            if Transpose:\n",
    "                Bkt = Akt @ V\n",
    "            else:\n",
    "                Bkt =  Akt @ V.T\n",
    "\n",
    "            B[k*nBk: (k+1) * nBk] = Bkt.ravel().reshape(-1, 1)\n",
    "\n",
    "    newsz = copy.copy(sz)\n",
    "    newsz[n] = p\n",
    "\n",
    "    # put it back in a tensor format\n",
    "    Y = Tensor(B)\n",
    "\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc63b07f-e0e8-417a-8cac-1467848ecc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tensors import matricization\n",
    "\n",
    "def nvecs(X,n,r,options=None):\n",
    "    \"\"\"\n",
    "        This function computes the leading mode-n vectors for a tensor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            Xn: The mode-n matricization of X.\n",
    "            n:  The n-th mode of the tensor X.\n",
    "            r:  Leading eigenvalue of Xn*Xn.T. This reveals information about the\n",
    "                mode-n fibers.\n",
    "            options: A Bundle class options hat packs computation options to be \n",
    "                     passed along to the decomposition solver.\n",
    "                     \n",
    "                     Parameters\n",
    "                     ----------\n",
    "                    .flipsign: make each column's largest element positive: Default: True\n",
    "                    .svd: use svds on Xn rather than np.linalg.eigs on Xn*Xn'; Default: False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            U: The left unitary (typically) orthogonal  mode-n matrix of X.\n",
    "\n",
    "        Remarks\n",
    "        -------\n",
    "            In two-dimensions, the r leading mode-1 vectors are the same as the r left\n",
    "            singular vectors and the r leading mode-2 vectors are the same as the r\n",
    "            right singular vectors. By default, this method computes the top r\n",
    "            eigenvectors of the matrix Xn*Xn^T. This behavior can be changed per the\n",
    "            options argument as follows:\n",
    "\n",
    "\n",
    "        Example:\n",
    "        --------\n",
    "           X = Tensor(npr.randn(3,2,3))\n",
    "           nvecs(X,3,2)\n",
    "\n",
    "        Author: Lekan Molux\n",
    "        Date: November 2, 2021\n",
    "    \"\"\"\n",
    "    global use_gpu\n",
    "\n",
    "    options = Bundle({}) if options is None  else options\n",
    "    options = Bundle(options) if isinstance(options, dict) else options\n",
    "\n",
    "    options.svd      = options.__dict__.get('svd', False)\n",
    "    options.flipsign = options.__dict__.get('flipsign', True)\n",
    "    options.rdims    = options.__dict__.get('rdims', np.arange(n, dtype=np.intp))\n",
    "    use_gpu          = options.__dict__.get('use_gpu', use_gpu)\n",
    "    \n",
    "    print('X: ', X.shape, 'options.rdims: ', options.rdims)\n",
    "    Xn = matricization(X, n)\n",
    "    \n",
    "    Xn = Xn().T.data\n",
    "    \n",
    "    print('Xmat: ', Xn.shape, 'r: ', r)\n",
    "    if isfield(options, 'svd') and options.svd:\n",
    "        if use_gpu:\n",
    "            Xn = cp.asarray(Xn) # Do it on gpu if available\n",
    "            U,_, _ = cp.linalg.svd(Xn, full_matrices=False)\n",
    "        else:\n",
    "            U,_, _ = np.linalg.svd(Xn, full_matrices=False)\n",
    "        # we are only interested in the first r values, so copy those\n",
    "        U = U[:,:r]\n",
    "    else:\n",
    "        Y = Xn @ Xn.T\n",
    "        if use_gpu:\n",
    "            Y = cp.asarray(Y) # Do it on gpu if available\n",
    "            try:\n",
    "                U = cp.linalg.eigvalsh(Y, 'U')\n",
    "            except:\n",
    "                LinAlgError(\"Could not find the leading eigen values using\"\n",
    "                            \"Numpy's eigvals method.\")\n",
    "            # move array back to host\n",
    "            U = U.get()\n",
    "        else:\n",
    "            try:\n",
    "                U = np.linalg.eigvalsh(Y, 'U')\n",
    "            except:\n",
    "                LinAlgError(\"Could not find the leading eigen values using\"\n",
    "                            \"Numpy's eigvals method.\")\n",
    "        print('U: ', U.shape)\n",
    "        # return only the leading 'r' values:\n",
    "        U = U[:,:r]\n",
    "\n",
    "    if isfield(options, 'flipsign') and options.flipsign:\n",
    "        # Make the largest magnitude element be positive\n",
    "        maxi = np.amax(np.abs(U))\n",
    "        maxi_idx = np.where(np.abs(U)==maxi)\n",
    "\n",
    "        for i in range(r):\n",
    "            if U[maxi_idx] < 0:\n",
    "                U[maxi_idx] *= -1\n",
    "\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "30572b92-5839-4fa4-b587-39de368941de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cupy.random as cpr\n",
    "# import numpy.random as npr\n",
    "# from Tensors.leading_vecs import nvecs\n",
    "\n",
    "## adhoc functions/classes we'll need to get things rolling\n",
    "class TuckerTensor():\n",
    "    def __init__(self, core, U):\n",
    "        \"\"\"\n",
    "            Tucker Tensor Class:\n",
    "                Decomposes a high-order tensor into its core component and \n",
    "                a set of (usually) unitary matrices associated with every\n",
    "                mode of the tensor.\n",
    "                \n",
    "            Params\n",
    "            ------\n",
    "            core: The core tensor, whose entries shows the interaction among \n",
    "                  its components\n",
    "            U:    The factor matrices (typically orthogonal:=principal components\n",
    "                    in each mode)\n",
    "                    \n",
    "            Author: Lekan Molux\n",
    "            Date: November 2, 2021\n",
    "        \"\"\"\n",
    "        if isinstance(core, Tensor):\n",
    "            self.T = core\n",
    "        else:\n",
    "            self.T = Tensor(core, core.shape)\n",
    "        \n",
    "        self.U    = U\n",
    "        \n",
    "def tucker_als(X, R, **options):\n",
    "    \"\"\"\n",
    "        Performs Tucker's \"Method I\" for computing a rank \n",
    "        (R_1, R_2, \\cdots, R_N) Tucker decomposition, now known as HOSVD.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: Tensor to be decomposed\n",
    "        R: A single rank or best list of ranks to find in obtaining the Tucker SVD\n",
    "        options: {key:value} map of options to use in the alternating least square optimization\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        G: Core Tensor\n",
    "        [F_1, F_2, ...]: Factors of the Unitary Matrices for the modes of the tensor we are querying.\n",
    "        \n",
    "        Ref: Kolda and Baer Procedure HOSVD\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(X, Tensor):\n",
    "        X = X.data\n",
    "    \n",
    "    N = X.ndim\n",
    "    normX = np.linalg.norm(X)\n",
    "    \n",
    "    tol = options.get('tol', 1e-4)\n",
    "    max_iter = options.get('max_iter', 100)\n",
    "    dimorder = options.get('dimorder', list(range(N)))\n",
    "    init     = options.get('init', 'random')\n",
    "    verbose     = options.get('verbose', True)\n",
    "    verbose     = options.get('use_gpu', True)\n",
    "    \n",
    "    if numel(R)==1:\n",
    "        R *= np.ones((N, 1), dtype=np.int64)\n",
    "        if use_gpu:\n",
    "            R = cp.asarray(R)\n",
    "    U = cell(N)\n",
    "    \n",
    "    assert max_iter > 0, \"maximum number of iteratons cannot be negative\"\n",
    "    \n",
    "    Uinit = cell(len(dimorder))\n",
    "    if strcmp(init,'random'):\n",
    "        for n in dimorder:\n",
    "            Uinit[n] = npr.rand(size(X,n),R[n])\n",
    "    elif strcmp(init,'nvecs') or strcmp(init,'eigs'):\n",
    "        \"\"\"\n",
    "            Compute an orthonormal basis for the dominant\n",
    "            Rn-dimensional left singular subspace of\n",
    "            X_(n) (1 <= n <= N).\n",
    "        \"\"\"\n",
    "        for n in dimorder:\n",
    "            info(f'Computing {R[n]} leading e-vectors for factor {n}.')\n",
    "            Uinit[n] = nvecs(X,n,R[n])\n",
    "    else:\n",
    "        raise ValueError('The selected initialization method is not supported.')\n",
    "      \n",
    "    U = Uinit\n",
    "    fit = 0\n",
    "\n",
    "    if verbose:\n",
    "        info('Tucker Alternating Least-Squares:')\n",
    "    \n",
    "    # Function Motherlode: Iterate until convergence\n",
    "    for iter in range(max_iter):\n",
    "        fitold = fit\n",
    "        \n",
    "        # iterate over all N modes of the tensor        \n",
    "        for n in dimorder:\n",
    "            Utilde = tensor_matrix_mult(X, U, -n, Transpose=True, use_gpu=use_gpu)\n",
    "            \n",
    "            'Max the norm of (U_tilde x_n W.T) w.r.t W and keep the'\n",
    "            'orthonormality of W.'            \n",
    "            U[n] = nvecs(Utilde, n, R[n], options=Bundle({}))\n",
    "        \n",
    "        # Assemble the approx        \n",
    "        core = tensor_matrix_mult(Utilde, U, n, Transpose=True, use_gpu=use_gpu)\n",
    "        \n",
    "        # Compute the fit\n",
    "        normresidual = np.sqrt(normX**2 - norm(core)**2)\n",
    "        fit = 1- (normresidual/normX)\n",
    "        fitchange = np.abs(fitold-fit)\n",
    "        \n",
    "        if iter%5==0:\n",
    "            info(f\"Iter: {iter:2d}, fit: {fit:.4f}, fitdelta: {fitchange:7.1f}\")\n",
    "    \n",
    "        # Did we converge yet?\n",
    "        if iter>1 and fitchange < fitchangetol:\n",
    "            break\n",
    "        \n",
    "    T = TuckerTensor(core, U)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6d13b8cc-1db3-46a7-8429-de46760d54cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-4d9fff857707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mXX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker_als\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-117-a4e86a2e1c05>\u001b[0m in \u001b[0;36mtucker_als\u001b[0;34m(X, R, **options)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# iterate over all N modes of the tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdimorder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mUtilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_matrix_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;34m'Max the norm of (U_tilde x_n W.T) w.r.t W and keep the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Control-Rob/Reachability/LevelSetPy/Tensors/tensor_mat_mult.py\u001b[0m in \u001b[0;36mtensor_matrix_mult\u001b[0;34m(X, V, n, Transpose, use_gpu)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m'when we are multiplying with multiple arrays'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m'be careful that we do not give cupy object dtypes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'O'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "n, R, X = 1, [3,3,3], npr.rand(3,3,3)\n",
    "XX = tucker_als(X, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98b57a2f-07ec-4e21-b4ea-1e188165312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "       [19, 20, 21, 22, 23, 24, 25, 26, 27]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = np.arange(1, 28).reshape(3,3,3)\n",
    "XT = Tensor(X, X.shape)\n",
    "X1 = matricize_tensor([X, 0])\n",
    "X1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f3450f-75b1-4977-9600-558b7ea39ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "       [19, 20, 21, 22, 23, 24, 25, 26, 27]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be same as above \n",
    "X1 = matricize_tensor([XT, 0])\n",
    "X1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5b1bf1-51a6-405e-af05-41aa04fa0146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3, 10, 11, 12, 19, 20, 21],\n",
       "       [ 4,  5,  6, 13, 14, 15, 22, 23, 24],\n",
       "       [ 7,  8,  9, 16, 17, 18, 25, 26, 27]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode 1 of tensor\n",
    "X1 = matricize_tensor([XT, 1])\n",
    "X1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559043f2-a6f8-4a17-ba18-60f49d45f8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  7, 10, 13, 16, 19, 22, 25],\n",
       "       [ 2,  5,  8, 11, 14, 17, 20, 23, 26],\n",
       "       [ 3,  6,  9, 12, 15, 18, 21, 24, 27]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode 2 of tensor\n",
    "X2 = matricize_tensor([XT, 2])\n",
    "X2.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8c4967a-1021-4e66-8df0-f5722d192a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10, 19,  4, 13, 22,  7, 16, 25],\n",
       "       [ 2, 11, 20,  5, 14, 23,  8, 17, 26],\n",
       "       [ 3, 12, 21,  6, 15, 24,  9, 18, 27]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = np.arange(1, 28).reshape(3,3,3, order='F')\n",
    "# X = np.transpose(X, [2, 1, 0])\n",
    "X0 = matricize_tensor([X, 0])\n",
    "X0.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc537818-42a6-46b3-84b6-18df70a4ec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "       [19, 20, 21, 22, 23, 24, 25, 26, 27]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(1, 28).reshape(3, 3, 3, order='C')\n",
    "T = matricization(X, mode=2)\n",
    "T #.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89c54438-b60e-4993-bf03-87da8a5e791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "X.T [[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(9).reshape(3,3)\n",
    "print(f'X: {X}\\nX.T {X.T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cc5a361-0f65-4b12-bcc1-356bc0b9dc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  7,  2,  5,  8,  3,  6,  9],\n",
       "       [10, 13, 16, 11, 14, 17, 12, 15, 18],\n",
       "       [19, 22, 25, 20, 23, 26, 21, 24, 27]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23c83c-71d6-41bc-ac96-d19b7bc6aef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
